{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,  accuracy_score\n",
    "import random \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import gensim #library needed for word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://www.dropbox.com/s/ia4tpu47h5f5ptd/train.csv?raw=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)\n",
    "\n",
    "def take_data(data):\n",
    "    data = data.replace(np.nan, '', regex=True)\n",
    "    return data['Plot']+data['Title']+data['Director']+data['Cast']#+data['Origin/Ethnicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Andreas\n",
      "[nltk_data]     Pap\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk_stops = stopwords.words('english')\n",
    "vectorizer = TfidfVectorizer(max_features=15000,\n",
    "                             stop_words = nltk_stops,\n",
    "                             max_df=.7)\n",
    "data = take_data(df)\n",
    "vectorizer.fit(data)\n",
    "df_tf = vectorizer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6153    Jessie is a middle-aged woman living with her ...\n",
       "8309    At the beginning of the film, D.M.C. is releas...\n",
       "3035    In 1980, an annual gathering of teams of idios...\n",
       "6036    Paul Kersey (Charles Bronson) returns to New Y...\n",
       "2722    After the death of his girlfriend, Suzuki (Iku...\n",
       "9195    Recently widowed Michelle O'Brien moves into a...\n",
       "1820    In 1988 San Dimas, California, slackers Bill a...\n",
       "2904    \"The film does not present a linear story; rat...\n",
       "2254    The twin cities of Sodom and Gomorrah prosper ...\n",
       "3398    San Francisco Assistant District Attorney Davi...\n",
       "Name: Plot, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Plot'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = LR(max_iter=1000,class_weight='balanced' , solver='liblinear')\n",
    "classifier = RF()#n_estimators= 1200, max_depth= 30, min_samples_split=5)\n",
    "#classifier = svm.SVC(kernel='rbf', gamma=0.2)\n",
    "#classifier = MLPClassifier(solver='lbfgs',alpha=1e-5, hidden_layer_sizes=(5, 2))\n",
    "#classifier = GB(n_estimators=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 20.9min finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_estimators = [100, 200, 500, 1000,1200]\n",
    "max_depth = [2, 5, 10, 20, 30]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10] \n",
    "\n",
    "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "             min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "gridF = GridSearchCV(classifier, hyperF, cv = 3, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = gridF.fit(df_tf,df['Genre'])\n",
    "\n",
    "test = pd.read_csv('https://www.dropbox.com/s/7mjx3ulzrf2pde5/test.csv?raw=1')\n",
    "test_tf = vectorizer.transform(take_data(test))\n",
    "test['Predicted'] = bestF.best_estimator_.predict(test_tf)\n",
    "test[['Id','Predicted']].to_csv(f'test_submissionsCHECK{random.randint(50,5000)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RF(n_estimators= 1200, max_depth= 30, min_samples_split=5)\n",
    "classifier.fit(df_tf,df['Genre'])\n",
    "\n",
    "test = pd.read_csv('https://www.dropbox.com/s/7mjx3ulzrf2pde5/test.csv?raw=1')\n",
    "test_tf = vectorizer.transform(take_data(test))\n",
    "test['Predicted'] = classifier(test_tf)\n",
    "test[['Id','Predicted']].to_csv('test_submissionsRF.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LR(max_iter=1000,class_weight='balanced' , solver='liblinear')\n",
    "classifier.fit(df_tf,df['Genre'])\n",
    "\n",
    "test = pd.read_csv('https://www.dropbox.com/s/7mjx3ulzrf2pde5/test.csv?raw=1')\n",
    "test_tf = vectorizer.transform(take_data(test))\n",
    "test['Predicted'] = classifier(test_tf)\n",
    "test[['Id','Predicted']].to_csv('test_submissionsLR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 1200}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestF.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
